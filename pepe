import requests
import os
from datetime import datetime, timedelta

def download_monthly_data(symbol, start_date, end_date, output_dir):
    current_date = start_date
    while current_date <= end_date:
        year = current_date.strftime("%Y")
        month = current_date.strftime("%m")
        url = f"https://data.binance.vision/data/spot/monthly/klines/{symbol}/1m/{symbol}-1m-{year}-{month}.zip"
        output_file = f"{symbol}-1m-{year}-{month}.zip"
        
        # 创建输出目录(如果不存在)
        os.makedirs(output_dir, exist_ok=True)
        
        # 发送GET请求并下载文件
        response = requests.get(url)
        with open(os.path.join(output_dir, output_file), "wb") as file:
            file.write(response.content)
        
        print(f"文件 {output_file} 下载完成!")
        
        # 更新当前日期为下个月的第一天
        current_date = current_date + timedelta(days=32)
        current_date = datetime(current_date.year, current_date.month, 1)

# 设置参数
symbol = "PEPEUSDT"
start_date = datetime(2023, 1, 1)
end_date = datetime(2024, 4, 30)
output_dir = "D:/1m"

# 调用函数下载数据
download_monthly_data(symbol, start_date, end_date, output_dir)

import os
import zipfile

def extract_files(directory):
    for filename in os.listdir(directory):
        if filename.endswith(".zip"):
            try:
                file_path = os.path.join(directory, filename)
                with zipfile.ZipFile(file_path, "r") as zip_ref:
                    zip_ref.extractall(directory)
                print(f"文件 {filename} 解压完成!")
            except:pass
# 设置数据文件所在的目录
data_directory = "D:/1m"

# 调用函数解压文件
extract_files(data_directory)


import requests
import json
import time
from datetime import datetime, timedelta

# Binance API的基础URL
base_url = 'https://api.binance.com'

# 指定交易对,如PEPEUSDT
symbol = 'PEPEUSDT'

# 指定时间间隔,1m表示5分钟
interval = '1m'

# 指定开始时间为2024年4月1日0点
start_time = datetime(2024, 4, 1, 8, 0, 0)

# 获取当前时间
now = datetime.now()

# 计算时间差并将其转换为秒数
time_diff = now - start_time
time_diff_seconds = time_diff.total_seconds()

# 计算5分钟的时间间隔对应的秒数
interval_seconds = 60*24 * 60

# 计算需要获取的数据条数
total_limit = int(time_diff_seconds // interval_seconds) + 1

# 每次请求获取的数据条数
batch_size = 1000

# 初始化开始时间戳
start_timestamp = int(start_time.timestamp() * 1000)
alldatas=[]

fs=glob.glob('D:/1m/PEPEUSDT-1m-*csv')#[:-1]

df=pd.concat([pd.read_csv(f,header=None) for f in fs])
df=pd.DataFrame(df.values,columns=['Open time','Open','High','Low','Close','Volume','Close time','Quote asset volume','Number of trades','Taker buy base asset volume','Taker buy quote asset volume','Ignore'])

df=df.drop_duplicates()

df.index=range(len(df))

df['buy_ratio1']=df['Taker buy base asset volume']/df['Volume']

df['buy_ratio2']=df['Taker buy quote asset volume']/df['Quote asset volume']

df.to_parquet('D:/1m/PEPEUSDT_1m_all.parquet')





from scipy.stats import linregress
import pandas as pd
import numpy as np
from scipy import signal
from sklearn.metrics.pairwise import cosine_similarity
from statsmodels.tsa.stattools import coint
from scipy.stats import skew, kurtosis

class FT:

    def __init__(self, df, windows=[5, 10, 20, 30, 60], return_ma_windows=[5], price_fields=['Open', 'High', 'Low', 'Close'], vol_fields=['Volume']):
        self.df = df
        self.windows = windows
        self.return_ma_windows = return_ma_windows
        self.price_fields = price_fields
        self.vol_fields = vol_fields  
        self.feature_names = []

    def calculate(self):
        features_data = {}
        
        # 计算价格类因子
        for field in self.price_fields:
            features_data=self.cal_price_field(field, features_data)
        
        # 计算交易量类因子
        for field in self.vol_fields:
            features_data=self.cal_vol_field(field, features_data)
        
        # 计算价量组合类因子 
        features_data=self.cal_price_vol_factors(features_data)
        
        # 计算收益率类因子
        features_data=self.cal_return_factors(features_data)
        
        # 计算其他类型因子
        features_data=self.cal_other_factors(features_data)
        
        self.features = pd.DataFrame(features_data, index=self.df.index)
        return self.features

    def cal_return_factors(self, features_data):
        for d in self.return_ma_windows:
            col = f'return_ma_{d}'
            features_data[col] = self.df['Close'].pct_change(d).rolling(d).mean()
            self.feature_names.append(col)
        return features_data
    def cal_price_field(self, field, features_data):
        for d in self.windows:
            # ROC
            col = f'{field}_roc_{d}' 
            features_data[col] = self.df[field].shift(d) / self.df[field]
            self.feature_names.append(col)
            
            # MA
            col = f'{field}_ma_{d}'
            features_data[col] = self.df[field].rolling(d).mean() 
            self.feature_names.append(col)
            
            # STD
            col = f'{field}_std_{d}'
            features_data[col] = self.df[field].rolling(d).std()
            self.feature_names.append(col)
            
            # Beta
            col = f'{field}_beta_{d}'
            features_data[col] = self.beta(self.df[field], d)
            self.feature_names.append(col)
            
            # 20% Quantile
            col = f'{field}_q20_{d}'
            features_data[col] = self.df[field].rolling(d).quantile(0.2)
            self.feature_names.append(col)
            
            # 80% Quantile
            col = f'{field}_q80_{d}'
            features_data[col] = self.df[field].rolling(d).quantile(0.8)
            self.feature_names.append(col)
            
            # Min
            col = f'{field}_min_{d}'
            features_data[col] = self.df[field].rolling(d).min()
            self.feature_names.append(col)
            
            # Max
            col = f'{field}_max_{d}'
            features_data[col] = self.df[field].rolling(d).max()
            self.feature_names.append(col)

        return features_data
    def cal_vol_field(self, field, features_data):
        for d in self.windows:
            # ROC
            col = f'{field}_roc_{d}'
            features_data[col] = (self.df[field].shift(d) - self.df[field]) / self.df[field]
            self.feature_names.append(col)
            
            # MA  
            col = f'{field}_ma_{d}'
            features_data[col] = self.df[field].rolling(d).mean()
            self.feature_names.append(col)
            
            # STD
            col = f'{field}_std_{d}'
            features_data[col] = self.df[field].rolling(d).std()
            self.feature_names.append(col)

        return features_data
    def cal_price_vol_factors(self, features_data):
        for d in self.windows:
            # 价格/成交量
            col = f'price_volume_roc_{d}'
            features_data[col] = (self.df['Close'].shift(d) - self.df['Close']) / (self.df['Volume'].shift(d) - self.df['Volume'])
            self.feature_names.append(col)

            col = f'price_volume_ma_{d}'  
            features_data[col] = self.df['Close'].rolling(d).mean() / self.df['Volume'].rolling(d).mean()
            self.feature_names.append(col)
            
            # 成交额
            col = f'amount_ma_{d}'
            features_data[col] = (self.df['Close'] * self.df['Volume']).rolling(d).mean()
            self.feature_names.append(col)
            
            # 加权成交量
            col = f'wvma_{d}'
            features_data[col] = self.wvma(d)
            self.feature_names.append(col)
            
            # 交易量动量（正/负）
            col = f'v_sump_{d}'
            features_data[col] = self.df['Volume'][self.df['Close'] > self.df['Close'].shift(1)].rolling(d).sum()
            self.feature_names.append(col)
            
            col = f'v_sumn_{d}'
            features_data[col] = self.df['Volume'][self.df['Close'] < self.df['Close'].shift(1)].rolling(d).sum() 
            self.feature_names.append(col)
            
            # 心理线
            col = f'psy_line_{d}'
            features_data[col] = self.psy_line(d)
            self.feature_names.append(col)

        return features_data
    def cal_other_factors(self, features_data):
        max_length = max(len(self.df), max(len(v) for v in features_data.values()))
        for d in self.windows:
            # Fractal Dimension
            col = 'fractal_dimension_hausdorff_%d' % d
            features_data[col] = self.factor_fractal_dimension(d)
            self.feature_names.append(col)
            col = 'fractal_dimension_hurst_%d' % d
            features_data[col] = self.factor_fractal_dimension(d,'hurst')
            self.feature_names.append(col)

            # Smart Money Flow  
            col = 'smart_money_flow_%d' % d
            features_data[col] = np.log(self.df['High']-self.df['Low']) * np.log(self.df['Volume']) * (self.df['Close']-self.df['Open'])/self.df['Open']
            self.feature_names.append(col)

            # Momentum Reversal
            col = 'momentum_reversal_%d' % d
            features_data[col] = self.df['Close'].pct_change(d) * self.df['Close'].pct_change(1) 
            self.feature_names.append(col)

            # Jump Risk
            col = 'jump_risk_005_%d' % d
            jump = (self.df['High'] - self.df['Low']) / self.df['Open'] > 0.05
            features_data[col] = jump.rolling(d).mean()
            self.feature_names.append(col)

            col = 'jump_risk_01_%d' % d  
            jump = (self.df['High'] - self.df['Low']) / self.df['Open'] > 0.1
            features_data[col] = jump.rolling(d).mean()
            self.feature_names.append(col)

            # Pos Neg Volume
            col = 'pos_neg_volume_%d' % d
            pos_vol = self.df['Volume'][self.df['Close']>self.df['Open']].rolling(d).sum()
            neg_vol = self.df['Volume'][self.df['Close']<=self.df['Open']].rolling(d).sum()
            features_data[col] = pos_vol / (pos_vol + neg_vol + 1e-8) 
            self.feature_names.append(col)

            # Average Candle Body/Shadow
            col = 'avg_candle_body_%d' % d
            body = abs(self.df['Close'] - self.df['Open']) 
            features_data[col] = body.rolling(d).mean()
            self.feature_names.append(col)

            col = 'avg_candle_shadow_%d' % d
            wick = (self.df['High'] - self.df[['Open','Close']].max(axis=1)) + (self.df[['Open','Close']].min(axis=1) - self.df['Low'])
            features_data[col] = wick.rolling(d).mean()
            self.feature_names.append(col)

            # Information Ratio
            col = 'information_ratio_%d' % d
            ret = self.df['Close'].pct_change()
            features_data[col] = ret.rolling(d).mean() / ret.rolling(d).std()
            self.feature_names.append(col)

            # Volume Burst
            col = 'volume_burst_%d' % d
            features_data[col] = self.df['Volume'] / self.df['Volume'].rolling(d).max()
            self.feature_names.append(col)

            # Price Breakout  
            col = 'price_breakout_%d' % d
            price_change = (self.df['Close'] - self.df['Close'].shift(d)) / self.df['Close'].shift(d)
            features_data[col] = price_change
            self.feature_names.append(col)


            # Price Oscillation
            col = 'price_oscillation_%d' % d  
            osc_range = (self.df['High'].rolling(d).max() - self.df['Low'].rolling(d).min()) / self.df['Close'].rolling(d).mean()
            features_data[col] = osc_range  
            self.feature_names.append(col)

            # Volume Price Divergence  
            col = 'volume_price_divergence_%d' % d
            p_change = self.df['Close'].pct_change(d)
            v_change = self.df['Volume'].pct_change(d) 
            features_data[col] = p_change - v_change
            self.feature_names.append(col)

            # VWAP
            col = 'vwap_%d' % d
            vwap = (self.df['Volume'] * (self.df['High']+self.df['Low']+self.df['Close'])/3).rolling(d).sum() / self.df['Volume'].rolling(d).sum()
            features_data[col] = self.df['Close'] / vwap
            self.feature_names.append(col)

        for d1,d2 in [(5,10),(10,20),(20,60)]:  
            # RS Ratio
            col = 'rs_ratio_%d_%d' % (d1,d2)
            rs = self.df['Close'].pct_change(d1).rolling(d1).mean() / self.df['Close'].pct_change(d2).rolling(d2).mean()
            features_data[col] = rs
            self.feature_names.append(col)

            # SMA Crossover
            col = 'sma_crossover_%d_%d' % (d1, d2)
            sma1 = self.df['Close'].rolling(d1).mean()
            sma2 = self.df['Close'].rolling(d2).mean()
            features_data[col] = np.where(sma1>sma2, 1, -1)
            self.feature_names.append(col)

        # Return distribution 
        for d in self.windows:
            ret = self.df['Close'].pct_change(d)

            col = 'return_skewness_%d' % d
            features_data[col] = ret.rolling(d).skew()
            self.feature_names.append(col)

            col = 'return_kurtosis_%d' % d  
            features_data[col] = ret.rolling(d).kurt()
            self.feature_names.append(col)

        # Candle type
        for d in self.windows:
            green = (self.df['Close'] > self.df['Open']).astype(int)

            col = 'bullish_candle_ratio_%d' % d
            bull_count = green.rolling(d).sum()
            features_data[col] = bull_count / d
            self.feature_names.append(col)

        # Turnover
        for d in self.windows:  
            col = 'turnover_rate_%d' % d
            turnover = self.df['Volume'].rolling(d).sum() / self.df['Volume'].rolling(d).mean() 
            features_data[col] = turnover
            self.feature_names.append(col)

        # Abnormal trading pattern
        for d in self.windows:
            vol_ma = self.df['Volume'].rolling(d).mean()
            vol_std = self.df['Volume'].rolling(d).std()
            col = 'abnormal_trading_pattern_2_%d' % d
            features_data[col] = (self.df['Volume'] > vol_ma + 2*vol_std).astype(int)
            self.feature_names.append(col)

            col = 'abnormal_trading_pattern_3_%d' % d
            features_data[col] = (self.df['Volume'] > vol_ma + 3*vol_std).astype(int)
            self.feature_names.append(col)

        # Price volume correlation  
        for d in self.windows:
            ret = np.log(self.df['Close']).diff()
            vol = np.log(self.df['Volume'])

            col = 'price_volume_corr_%d' % d
            features_data[col] = ret.rolling(d).corr(vol)
            self.feature_names.append(col)
            
        # Price/Volume Cointegration
        for d in self.windows:
            col = 'price_volume_cointegration_%d' % d
            features_data[col] = self.factor_price_volume_cointegration(d)
            self.feature_names.append(col)

        # Abnormal Volume
        for d in self.windows:
            col = 'abnormal_volume_%d' % d
            features_data[col] = self.factor_abnormal_volume(d)
            self.feature_names.append(col)

        # Volume High/Low
        for d in self.windows:
            col = 'volume_high_low_%d' % d
            features_data[col] = self.factor_volume_high_low(d) 
            self.feature_names.append(col)

        # Price High/Low
        for d in self.windows:
            col = 'price_high_low_%d' % d
            features_data[col] = self.factor_price_high_low(d)
            self.feature_names.append(col)

        # Price COG
        for d in self.windows:
            col = 'price_cog_%d' % d
            features_data[col] = self.factor_price_cog(d)
            self.feature_names.append(col)

        # Price/Volume Correlation
        for d in self.windows:
            col = 'p_v_corr0_%d' % d
            features_data[col] = self.factor_price_volume_corr0(d)
            self.feature_names.append(col)

        for d in self.windows:
            col = 'p_v_corr1_%d' % d
            features_data[col] = self.factor_price_volume_corr1(d)
            self.feature_names.append(col)

        for d in self.windows:
            col = 'p_v_cord_%d' % d
            features_data[col] = self.factor_price_volume_cord(d)
            self.feature_names.append(col)
        # Money Flow
        for d in self.windows:
            col = 'money_flow_%d' % d
            features_data[col] = self.factor_money_flow(d)
            self.feature_names.append(col)

        # Order Imbalance
        for d in self.windows:
            col = 'order_imbalance_%d' % d
            features_data[col] = self.factor_order_imbalance(d)
            self.feature_names.append(col)

        # Price/Volume Volatility
        for d in self.windows:
            col = 'price_volatility_%d' % d
            features_data[col] = self.factor_price_volatility(d)
            self.feature_names.append(col)
            
            col = 'volume_volatility_%d' % d
            features_data[col] = self.factor_volume_volatility(d)
            self.feature_names.append(col)
        for k, v in features_data.items():
            if len(v) < max_length:
                features_data[k] = np.concatenate((np.nan*np.zeros(max_length - len(v)),v.values.flatten()))
        #features_data['feature_name'] = self.feature_names
        return features_data

    def hurst_exponent(self, series, window):
        if len(series) < window:
            return np.nan
        lags = range(2, window)
        tau = [np.sqrt(np.std(np.subtract(series[lag:], series[:-lag]))) for lag in lags]
        poly = np.polyfit(np.log(lags), np.log(tau), 1)
        return poly[0]*2.0

    def factor_price_volume_corr0(self, n):
        price = self.df['Close'].pct_change()
        volume = self.df['Volume'].pct_change()
        corr = price.rolling(n).corr(volume)
        return corr

    def factor_price_volume_corr1(self, d):
        return self.df['Close'].rolling(d).corr(np.log(self.df['Volume']+1))
    def factor_price_volume_cord(self, d):
        price_change = self.df['Close'] / self.df['Close'].shift(1)
        vol_change = self.df['Volume'] / self.df['Volume'].shift(1) 
        return price_change.rolling(d).corr(np.log(vol_change+1))

    def factor_price_volume_cointegration(self, n):
        price = self.df['Close'].replace(np.inf,np.nan).replace(-np.inf,np.nan).fillna(method='ffill').fillna(0)
        volume = self.df['Volume'].replace(np.inf,np.nan).replace(-np.inf,np.nan).fillna(method='ffill').fillna(0)
        _, pvalue, _ = coint(price[-n:], volume[-n:])
        return pd.Series(np.full(self.df.shape[0], pvalue), index=self.df.index)
        
    def factor_sma_crossover(self, n1, n2):
        sma1 = self.df['Close'].rolling(n1).mean()
        sma2 = self.df['Close'].rolling(n2).mean()
        crossover = (sma1 > sma2).astype(int) - (sma1 < sma2).astype(int)
        return crossover

    def factor_price_high_low(self, n):
        high = (self.df['High'] == self.df['High'].rolling(n).max()).astype(int)
        low = (self.df['Low'] == self.df['Low'].rolling(n).min()).astype(int)
        return high - low
    
    def factor_volume_high_low(self, n):  
        high = (self.df['Volume'] == self.df['Volume'].rolling(n).max()).astype(int)
        low = (self.df['Volume'] == self.df['Volume'].rolling(n).min()).astype(int)
        return high - low
    
    def factor_price_volatility(self, n):
        return self.df['Close'].pct_change().rolling(n).std()

    def factor_volume_volatility(self, n):
        return self.df['Volume'].pct_change().rolling(n).std() 
    
    def factor_order_imbalance(self, n):
        buy_volume = self.df['Volume'][self.df['Close'] > self.df['Open']]
        sell_volume = self.df['Volume'][self.df['Close'] < self.df['Open']]
        buy_volume = buy_volume.fillna(0)
        sell_volume = sell_volume.fillna(0)
        imbalance = (buy_volume - sell_volume).rolling(n).sum() / self.df['Volume'].rolling(n).sum()
        return imbalance

    def factor_abnormal_volume(self, n):
        return self.df['Volume'] / self.df['Volume'].rolling(n).mean()

    def factor_price_cog(self, n):
        high = self.df['High'].rolling(n).mean() 
        low = self.df['Low'].rolling(n).mean()
        return (high + low) / 2

    def factor_vwap(self, n):
        vwap = (self.df['Close'] * self.df['Volume']).rolling(n).sum() / self.df['Volume'].rolling(n).sum()
        return self.df['Close'] / vwap

    def factor_money_flow(self, n):
        typical_price = (self.df['High'] + self.df['Low'] + self.df['Close']) / 3
        money_flow = typical_price * self.df['Volume']
        mf_ratio = money_flow.rolling(n).sum() / self.df['Volume'].rolling(n).sum()
        return mf_ratio

    def factor_pos_neg_volume(self, n):
        pos_volume = self.df['Volume'][self.df['Close'] > self.df['Close'].shift(1)].rolling(n).sum()
        neg_volume = self.df['Volume'][self.df['Close'] < self.df['Close'].shift(1)].rolling(n).sum()
        return pos_volume / neg_volume

    def factor_avg_candle_body(self, n):
        candle_body = abs(self.df['Close'] - self.df['Open'])
        return candle_body.rolling(n).mean()

    def factor_avg_candle_shadow(self, n):
        upper_shadow = self.df['High'] - self.df[['Close', 'Open']].max(axis=1)
        lower_shadow = self.df[['Close', 'Open']].min(axis=1) - self.df['Low']
        total_shadow = (upper_shadow + lower_shadow).rolling(n).mean()
        return total_shadow

    def factor_information_ratio(self, n):
        returns = self.df['Close'].pct_change()
        ir = returns.rolling(n).mean() / returns.rolling(n).std()
        return ir

    def factor_rs_ratio(self, n1, n2):
        rs = self.df['Close'].rolling(n1).mean() / self.df['Close'].rolling(n2).mean()
        return rs

    def factor_volume_burst(self, n):
        volume_burst = self.df['Volume'] / self.df['Volume'].rolling(n).max()
        return volume_burst

    def factor_price_breakout(self, n):
        breakout = (self.df['Close'] - self.df['Close'].shift(n)) / self.df['Close'].shift(n)
        return breakout

    def factor_price_oscillation(self, n):
        osc_range = (self.df['High'].rolling(n).max() - self.df['Low'].rolling(n).min()) / self.df['Close'].rolling(n).mean()
        return osc_range

    def factor_volume_price_divergence(self, n):
        price_change = self.df['Close'].pct_change(n)
        volume_change = self.df['Volume'].pct_change(n)
        divergence = price_change - volume_change
        return divergence

    def factor_smart_money_flow(self, n):
        smart_money_flow = self.df['Close'] * self.df['Volume'] * (self.df['Close'] - self.df['Open']) / (self.df['High'] - self.df['Low'])
        return smart_money_flow.rolling(n).sum()

    def factor_momentum_reversal(self, n):
        return_sign = np.sign(self.df['Close'].pct_change(n))
        reversal = (return_sign != return_sign.shift(1)).astype(int)
        return reversal

    def factor_jump_risk(self, n, threshold=0.05):  
        jump = (self.df['High'] - self.df['Low']) / self.df['Open'] > threshold
        jump_ma = jump.rolling(n).mean()
        return jump_ma
    
    def factor_fractal_dimension(self, n, method='hausdorff'):
        price = self.df['Close'].values
        rs = np.log(price[1:] / price[:-1])
        if method == 'hausdorff':
            fd = 2 - np.log(np.sum(np.absolute(rs))) / np.log(n)
        elif method == 'hurst':
            fd = 2 - self.hurst_exponent(rs, n)
        else:
            raise ValueError(f"Unsupported method: {method}")
        return pd.Series(np.full(self.df.shape[0], fd), index=self.df.index, name=f'FractalDimension_{n}_{method}')

    def factor_abnormal_trading_pattern(self, n, threshold=2):
        volume_mean = self.df['Volume'].rolling(n).mean()
        volume_std = self.df['Volume'].rolling(n).std()
        abnormal_volume = (self.df['Volume'] > volume_mean + threshold * volume_std).astype(int)
        return abnormal_volume
        
    def psy_line(self, n):
        psy = self.df['Close'].diff().apply(lambda x: 1 if x > 0 else 0).rolling(n).sum() / n
        return psy

    def wvma(self, n):
        vol_ma = self.df['Volume'].rolling(n).mean()
        wvma = (self.df['Volume'] * self.df['Close']).rolling(n).sum() / vol_ma
        return wvma

    def beta(self, series, n):
        returns = series.pct_change()
        market_returns = self.df['Close'].pct_change()
        cov = returns.rolling(n).cov(market_returns)
        market_var = market_returns.rolling(n).var()
        beta = cov / market_var
        return beta

import pandas as pd
import pandas as pd
# 读取原始数据
symbol=sym='PEPEUSDT'
df = pd.read_parquet(f'/hy-tmp/1m/{symbol}_1m_all.parquet')
import datetime
# 创建 Alpha158 实例
ft = FT(df)

# 计算因子特征
features = ft.calculate()

# 将因子特征保存为新的 Parquet 文件
output_path = f'/hy-tmp/1m/features03_{symbol}_1m_all.parquet'  # 替换为你要保存的文件路径
features.to_parquet(output_path)







symbol=sym='PEPEUSDT'
df=pd.read_parquet(f'/hy-tmp/1m/{symbol}_1m_all.parquet')
features=pd.read_parquet(f'/hy-tmp/1m/features03_{symbol}_1m_all.parquet')
import datetime

ori=39000+6000-62*96-96*50-96*180

for c in df.columns:features[c]=df[c]
features['buy_ratio1']=df['Taker buy base asset volume']/df['Volume']
features['buy_ratio2']=df['Taker buy quote asset volume']/df['Quote asset volume']
df['target']=df['Close'].pct_change().shift(-1)
ori=200000
preds=[]
gap=0
#preds=[np.load(f'catgenerate_factors31000_0.1_6noagg{sym}{ori}1mdata1mpred.npy')]
#gap=len(np.load(f'catgenerate_factors31000_0.1_6noagg{sym}{ori}1mdata1mpred.npy'))
from catboost import CatBoostRegressor
try:features=features.drop(['target'],axis=1)
except:pass
predstrue=[]
for startidx in range(ori+gap,len(df)+1,4*24*90*15):
    print(startidx)
#try:
    model = CatBoostRegressor(task_type="GPU",thread_count=-1,n_estimators=1000,max_depth=6,learning_rate=0.1, verbose=0)
    model.fit(features.iloc[:startidx-1], df['target'].iloc[:startidx-1].fillna(0))
    predstrue.append(model.predict(features.iloc[startidx:(startidx+96*90*15)]))
    np.save(f'90daycatf031000_0.1_6noaggspot{sym}{ori}1mdata1mpred.npy',np.concatenate((predstrue)))
    pred0=model.predict((features.iloc[:startidx-1]))
    targetgap=np.abs(df['target'].iloc[:startidx-1].fillna(0).values.flatten()-pred0)
    model = CatBoostRegressor(task_type="GPU",thread_count=-1,n_estimators=1000,max_depth=6,learning_rate=0.1, verbose=0)
    model.fit(features.iloc[:startidx-1], targetgap)
    pred=model.predict(features.iloc[startidx:(startidx+96*90*15)])
    #except:pred=np.zeros(96*20*15)
    preds.append(pred)
    np.save(f'prob_90daycatf031000_0.1_6noaggspot{sym}{ori}1mdata1mpred.npy',np.concatenate((preds)))
#except:pass



#################PEPEUSDT 1m
import requests
import json
import time
from datetime import datetime, timedelta
import os

os.environ['https_proxy'] = 'http://127.0.0.1:7890/'
os.environ['http_proxy'] = 'http://127.0.0.1:7890/'

# Binance API的基础URL
base_url = 'https://api.binance.com'

# 指定交易对,如PEPEUSDT
symbol = 'PEPEUSDT'

# 指定时间间隔,5m表示5分钟
interval = '1m'
now = datetime.now()
from datetime import datetime, timedelta

now = datetime.now()

# 获取当前日期的前一天
previous_day = now.date() - timedelta(days=1)

# 将前一天的日期设置为0点0分0秒
#start_time = datetime(previous_day.year, previous_day.month, previous_day.day, 6, 0, 0)
now=now.replace(minute=int(now.minute//1)*1,second=0,microsecond=0)
start_time=now - timedelta(minutes=1*200)
# 计算时间差并将其转换为秒数
time_diff = now - start_time
time_diff_seconds = time_diff.total_seconds()

# 计算5分钟的时间间隔对应的秒数
interval_seconds = 1 * 60

# 计算需要获取的数据条数
total_limit = int(time_diff_seconds // interval_seconds) + 1

# 每次请求获取的数据条数
batch_size = 1000

# 初始化开始时间戳
start_timestamp = int(start_time.timestamp() * 1000)
alldatas=[]
while total_limit > 0:
    #try:
        # 计算每次请求的数据条数
        limit = min(batch_size, total_limit)

        # 构建请求的URL
        url = f'{base_url}/api/v3/klines?symbol={symbol}&interval={interval}&startTime={start_timestamp}&limit={limit}'

        # 发送GET请求
        response = requests.get(url)

        # 解析响应的JSON数据
        data = json.loads(response.text)
        if len(data) > 0:
            # 更新开始时间戳和剩余数据条数
            start_timestamp = data[-1][0] + interval_seconds * 1000
            total_limit -= limit
        alldatas+=data

        # 添加请求间隔时间,避免超过API限制
        #time.sleep(1)
import datetime
rollbardf=pd.DataFrame(np.array(alldatas).astype(np.float64),columns=['Open time','Open','High','Low','Close','Volume','Close time','Quote asset volume','Number of trades','Taker buy base asset volume','Taker buy quote asset volume','Ignore']).drop_duplicates()
rollbardf.index=range(len(rollbardf))

import datetime
rollbardf['time']=rollbardf['Open time'].apply(lambda x:datetime.datetime.fromtimestamp(x/1000)).apply(lambda x: str(x)+'+08:00')
#rollbardf=rollbardf.drop(['Open time'],axis=1)
rollbardf.set_index('time',inplace=True)
rollbardf.to_csv('autodl-tmp/PEPErollbardf')

def main():
    import requests
    import json
    import time
    from datetime import datetime, timedelta
    import os

    os.environ['https_proxy'] = 'http://127.0.0.1:7890/'
    os.environ['http_proxy'] = 'http://127.0.0.1:7890/'

    # Binance API的基础URL
    base_url = 'https://api.binance.com'

    # 指定交易对,如PEPEUSDT
    symbol = 'PEPEUSDT'

    # 指定时间间隔,5m表示5分钟
    interval = '1m'
    now = datetime.now()
    from datetime import datetime, timedelta

    now = datetime.now()

    # 将前一天的日期设置为0点0分0秒
    start_time = now-timedelta(minutes=30)
    start_time=start_time.replace(minute=int(start_time.minute//1)*1,second=0,microsecond=0)
    now=now.replace(minute=int(now.minute//1)*1,second=0,microsecond=0)
    # 计算时间差并将其转换为秒数
    time_diff = now - start_time
    time_diff_seconds = time_diff.total_seconds()

    # 计算5分钟的时间间隔对应的秒数
    interval_seconds = 1 * 60

    # 计算需要获取的数据条数
    total_limit = int(time_diff_seconds // interval_seconds) + 1

    # 每次请求获取的数据条数
    batch_size = 1000

    # 初始化开始时间戳
    start_timestamp = int(start_time.timestamp() * 1000)
    alldatas=[]
    while total_limit > 0:
        #try:
            # 计算每次请求的数据条数
            limit = min(batch_size, total_limit)

            # 构建请求的URL
            url = f'{base_url}/api/v3/klines?symbol={symbol}&interval={interval}&startTime={start_timestamp}&limit={limit}'

            # 发送GET请求
            response = requests.get(url)

            # 解析响应的JSON数据
            data = json.loads(response.text)
            if len(data) > 0:
                # 更新开始时间戳和剩余数据条数
                start_timestamp = data[-1][0] + interval_seconds * 1000
                total_limit -= limit
            alldatas+=data

            # 添加请求间隔时间,避免超过API限制
            #time.sleep(1)
    import datetime
    rollbardf=pd.DataFrame(np.array(alldatas).astype(np.float64),columns=['Open time','Open','High','Low','Close','Volume','Close time','Quote asset volume','Number of trades','Taker buy base asset volume','Taker buy quote asset volume','Ignore']).drop_duplicates()
    rollbardf.index=range(len(rollbardf))

    import datetime
    rollbardf['time']=rollbardf['Open time'].apply(lambda x:datetime.datetime.fromtimestamp(x/1000)).apply(lambda x: str(x)+'+08:00')
    #rollbardf=rollbardf.drop(['Open time'],axis=1)
    rollbardf.set_index('time',inplace=True)

    tmp=pd.concat([pd.read_csv('autodl-tmp/PEPErollbardf').set_index('time'),rollbardf],axis=0).drop_duplicates()#.drop_duplicates(keep='last')

    tmp['time']=tmp.index

    tmp.drop_duplicates(subset='time', keep='last').drop(['time'],axis=1).iloc[-210:].to_csv('autodl-tmp/PEPErollbardf')

from apscheduler.schedulers.blocking import BlockingScheduler
scheduler = BlockingScheduler()
scheduler.add_job(main, 'cron',  minute='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59') #实时下单
scheduler.start()

























import os

os.environ['https_proxy'] = 'http://127.0.0.1:7890/'
os.environ['http_proxy'] = 'http://127.0.0.1:7890/'

def mainrun():
    import os
    import math

    os.environ['https_proxy'] = 'http://127.0.0.1:7890/'
    os.environ['http_proxy'] = 'http://127.0.0.1:7890/'

    from ft import FT

    from datetime import datetime, timedelta
    import requests
    import json
    import time
    from datetime import datetime, timedelta
    import datetime
    rollbardf=pd.read_csv('autodl-tmp/PEPErollbardf').set_index('time')
    import binance
    import time
    import os
    import time
    import datetime
    from binance.client import Client
    API_KEY = 'dtZ8mQh0LWuytNqzfvDMN6sbJRTxpUbNJ9WKkT8YFRltLkir1ezmD1vCVv8Hz56p'
    API_SECRET = 'jufQS4dkzXTG3xjq7D9RbJzEc9h9jOdwBxY4RhwixWsl7wTWYIZI8DUd1DJKBPDl'
    # 创建Binance客户端实例
    client = Client(API_KEY, API_SECRET)
    client.SPOT_USE_BNB_FOR_FEES = True
    client.FUTURES_USE_BNB_FOR_FEES = True

    # 指定交易对
    symbol = "PEPEUSDT"

    # 获取今日0点的Unix毫秒时间戳
    today_0000 = int(datetime.datetime.combine(datetime.date.today(), datetime.time(0, 0, 0)).timestamp() * 1000)


    #while True:
    for _ in range(1):
        # 获取当前时间
        from datetime import datetime
        now = datetime.now()

        # 计算上一个1分钟的起始时间和结束时间
        end_time = now.replace(minute=now.minute // 1 * 1, second=0, microsecond=0)
        start_time = end_time - timedelta(minutes=1)
        from datetime import datetime, timedelta

        # Binance API的基础URL
        base_url = 'https://api.binance.com'

        # 指定交易对,如PEPEUSDT
        symbol = 'PEPEUSDT'

        # 指定时间间隔,5m表示5分钟
        interval = '1m'
        now = datetime.now()

        # 计算时间差并将其转换为秒数
        time_diff = now - start_time
        time_diff_seconds = time_diff.total_seconds()

        # 计算5分钟的时间间隔对应的秒数
        interval_seconds = 1 * 60

        # 计算需要获取的数据条数
        total_limit = int(time_diff_seconds // interval_seconds) + 1

        # 每次请求获取的数据条数
        batch_size = 1000

        # 初始化开始时间戳
        start_timestamp = int(start_time.timestamp() * 1000)
        alldatas=[]
        while total_limit > 0:
            #try:
                # 计算每次请求的数据条数
                limit = min(batch_size, total_limit)

                # 构建请求的URL
                url = f'{base_url}/api/v3/klines?symbol={symbol}&interval={interval}&startTime={start_timestamp}&limit={limit}'

                # 发送GET请求
                response = requests.get(url)

                # 解析响应的JSON数据
                data = json.loads(response.text)
                if len(data) > 0:
                    # 更新开始时间戳和剩余数据条数
                    start_timestamp = data[-1][0] + interval_seconds * 1000
                    total_limit -= limit
                alldatas+=data

                # 添加请求间隔时间,避免超过API限制
                #time.sleep(1)
        import datetime
        latestbardf=pd.DataFrame(np.array(alldatas).astype(np.float64),columns=['Open time','Open','High','Low','Close','Volume','Close time','Quote asset volume','Number of trades','Taker buy base asset volume','Taker buy quote asset volume','Ignore']).drop_duplicates()
        latestbardf.index=range(len(latestbardf))

        import datetime
        latestbardf['time']=latestbardf['Open time'].apply(lambda x:datetime.datetime.fromtimestamp(x/1000)).apply(lambda x: str(x)+'+08:00')
        #latestbardf=latestbardf.drop(['Open time'],axis=1)
        latestbardf.set_index('time',inplace=True)

        tmp=pd.concat([rollbardf,latestbardf],axis=0).drop_duplicates()
        tmp['time']=tmp.index
        rollbardf=tmp.drop_duplicates(subset='time', keep='last')
        rollbardf=rollbardf.set_index('time')
        from ft import FT
        alpha = FT(rollbardf)
        features0 = alpha.calculate()

        features0['buy_ratio1']=rollbardf['Taker buy base asset volume']/rollbardf['Volume']
        features0['buy_ratio2']=rollbardf['Taker buy quote asset volume']/rollbardf['Quote asset volume']

        features=pd.concat([rollbardf,features0],axis=1)
        features=features.loc[rollbardf.index]
        try:features=features.drop(['target'],axis=1)
        except:pass
        try:features=features.drop(['T'],axis=1)
        except:pass
        try:features=features.drop(['time'],axis=1)
        except:pass  
        import joblib
        model=joblib.load(f'PEPElatest')
        cols=['Open_roc_5', 'Open_ma_5', 'Open_std_5', 'Open_beta_5', 'Open_q20_5', 'Open_q80_5', 'Open_min_5', 'Open_max_5', 'Open_roc_10', 'Open_ma_10', 'Open_std_10', 'Open_beta_10', 'Open_q20_10', 'Open_q80_10', 'Open_min_10', 'Open_max_10', 'Open_roc_20', 'Open_ma_20', 'Open_std_20', 'Open_beta_20', 'Open_q20_20', 'Open_q80_20', 'Open_min_20', 'Open_max_20', 'Open_roc_30', 'Open_ma_30', 'Open_std_30', 'Open_beta_30', 'Open_q20_30', 'Open_q80_30', 'Open_min_30', 'Open_max_30', 'Open_roc_60', 'Open_ma_60', 'Open_std_60', 'Open_beta_60', 'Open_q20_60', 'Open_q80_60', 'Open_min_60', 'Open_max_60', 'High_roc_5', 'High_ma_5', 'High_std_5', 'High_beta_5', 'High_q20_5', 'High_q80_5', 'High_min_5', 'High_max_5', 'High_roc_10', 'High_ma_10', 'High_std_10', 'High_beta_10', 'High_q20_10', 'High_q80_10', 'High_min_10', 'High_max_10', 'High_roc_20', 'High_ma_20', 'High_std_20', 'High_beta_20', 'High_q20_20', 'High_q80_20', 'High_min_20', 'High_max_20', 'High_roc_30', 'High_ma_30', 'High_std_30', 'High_beta_30', 'High_q20_30', 'High_q80_30', 'High_min_30', 'High_max_30', 'High_roc_60', 'High_ma_60', 'High_std_60', 'High_beta_60', 'High_q20_60', 'High_q80_60', 'High_min_60', 'High_max_60', 'Low_roc_5', 'Low_ma_5', 'Low_std_5', 'Low_beta_5', 'Low_q20_5', 'Low_q80_5', 'Low_min_5', 'Low_max_5', 'Low_roc_10', 'Low_ma_10', 'Low_std_10', 'Low_beta_10', 'Low_q20_10', 'Low_q80_10', 'Low_min_10', 'Low_max_10', 'Low_roc_20', 'Low_ma_20', 'Low_std_20', 'Low_beta_20', 'Low_q20_20', 'Low_q80_20', 'Low_min_20', 'Low_max_20', 'Low_roc_30', 'Low_ma_30', 'Low_std_30', 'Low_beta_30', 'Low_q20_30', 'Low_q80_30', 'Low_min_30', 'Low_max_30', 'Low_roc_60', 'Low_ma_60', 'Low_std_60', 'Low_beta_60', 'Low_q20_60', 'Low_q80_60', 'Low_min_60', 'Low_max_60', 'Close_roc_5', 'Close_ma_5', 'Close_std_5', 'Close_beta_5', 'Close_q20_5', 'Close_q80_5', 'Close_min_5', 'Close_max_5', 'Close_roc_10', 'Close_ma_10', 'Close_std_10', 'Close_beta_10', 'Close_q20_10', 'Close_q80_10', 'Close_min_10', 'Close_max_10', 'Close_roc_20', 'Close_ma_20', 'Close_std_20', 'Close_beta_20', 'Close_q20_20', 'Close_q80_20', 'Close_min_20', 'Close_max_20', 'Close_roc_30', 'Close_ma_30', 'Close_std_30', 'Close_beta_30', 'Close_q20_30', 'Close_q80_30', 'Close_min_30', 'Close_max_30', 'Close_roc_60', 'Close_ma_60', 'Close_std_60', 'Close_beta_60', 'Close_q20_60', 'Close_q80_60', 'Close_min_60', 'Close_max_60', 'Volume_roc_5', 'Volume_ma_5', 'Volume_std_5', 'Volume_roc_10', 'Volume_ma_10', 'Volume_std_10', 'Volume_roc_20', 'Volume_ma_20', 'Volume_std_20', 'Volume_roc_30', 'Volume_ma_30', 'Volume_std_30', 'Volume_roc_60', 'Volume_ma_60', 'Volume_std_60', 'price_volume_roc_5', 'price_volume_ma_5', 'amount_ma_5', 'wvma_5', 'v_sump_5', 'v_sumn_5', 'psy_line_5', 'price_volume_roc_10', 'price_volume_ma_10', 'amount_ma_10', 'wvma_10', 'v_sump_10', 'v_sumn_10', 'psy_line_10', 'price_volume_roc_20', 'price_volume_ma_20', 'amount_ma_20', 'wvma_20', 'v_sump_20', 'v_sumn_20', 'psy_line_20', 'price_volume_roc_30', 'price_volume_ma_30', 'amount_ma_30', 'wvma_30', 'v_sump_30', 'v_sumn_30', 'psy_line_30', 'price_volume_roc_60', 'price_volume_ma_60', 'amount_ma_60', 'wvma_60', 'v_sump_60', 'v_sumn_60', 'psy_line_60', 'return_ma_5', 'fractal_dimension_hausdorff_5', 'fractal_dimension_hurst_5', 'smart_money_flow_5', 'momentum_reversal_5', 'jump_risk_005_5', 'jump_risk_01_5', 'pos_neg_volume_5', 'avg_candle_body_5', 'avg_candle_shadow_5', 'information_ratio_5', 'volume_burst_5', 'price_breakout_5', 'price_oscillation_5', 'volume_price_divergence_5', 'vwap_5', 'fractal_dimension_hausdorff_10', 'fractal_dimension_hurst_10', 'smart_money_flow_10', 'momentum_reversal_10', 'jump_risk_005_10', 'jump_risk_01_10', 'pos_neg_volume_10', 'avg_candle_body_10', 'avg_candle_shadow_10', 'information_ratio_10', 'volume_burst_10', 'price_breakout_10', 'price_oscillation_10', 'volume_price_divergence_10', 'vwap_10', 'fractal_dimension_hausdorff_20', 'fractal_dimension_hurst_20', 'smart_money_flow_20', 'momentum_reversal_20', 'jump_risk_005_20', 'jump_risk_01_20', 'pos_neg_volume_20', 'avg_candle_body_20', 'avg_candle_shadow_20', 'information_ratio_20', 'volume_burst_20', 'price_breakout_20', 'price_oscillation_20', 'volume_price_divergence_20', 'vwap_20', 'fractal_dimension_hausdorff_30', 'fractal_dimension_hurst_30', 'smart_money_flow_30', 'momentum_reversal_30', 'jump_risk_005_30', 'jump_risk_01_30', 'pos_neg_volume_30', 'avg_candle_body_30', 'avg_candle_shadow_30', 'information_ratio_30', 'volume_burst_30', 'price_breakout_30', 'price_oscillation_30', 'volume_price_divergence_30', 'vwap_30', 'fractal_dimension_hausdorff_60', 'fractal_dimension_hurst_60', 'smart_money_flow_60', 'momentum_reversal_60', 'jump_risk_005_60', 'jump_risk_01_60', 'pos_neg_volume_60', 'avg_candle_body_60', 'avg_candle_shadow_60', 'information_ratio_60', 'volume_burst_60', 'price_breakout_60', 'price_oscillation_60', 'volume_price_divergence_60', 'vwap_60', 'rs_ratio_5_10', 'sma_crossover_5_10', 'rs_ratio_10_20', 'sma_crossover_10_20', 'rs_ratio_20_60', 'sma_crossover_20_60', 'return_skewness_5', 'return_kurtosis_5', 'return_skewness_10', 'return_kurtosis_10', 'return_skewness_20', 'return_kurtosis_20', 'return_skewness_30', 'return_kurtosis_30', 'return_skewness_60', 'return_kurtosis_60', 'bullish_candle_ratio_5', 'bullish_candle_ratio_10', 'bullish_candle_ratio_20', 'bullish_candle_ratio_30', 'bullish_candle_ratio_60', 'turnover_rate_5', 'turnover_rate_10', 'turnover_rate_20', 'turnover_rate_30', 'turnover_rate_60', 'abnormal_trading_pattern_2_5', 'abnormal_trading_pattern_3_5', 'abnormal_trading_pattern_2_10', 'abnormal_trading_pattern_3_10', 'abnormal_trading_pattern_2_20', 'abnormal_trading_pattern_3_20', 'abnormal_trading_pattern_2_30', 'abnormal_trading_pattern_3_30', 'abnormal_trading_pattern_2_60', 'abnormal_trading_pattern_3_60', 'price_volume_corr_5', 'price_volume_corr_10', 'price_volume_corr_20', 'price_volume_corr_30', 'price_volume_corr_60', 'price_volume_cointegration_5', 'price_volume_cointegration_10', 'price_volume_cointegration_20', 'price_volume_cointegration_30', 'price_volume_cointegration_60', 'abnormal_volume_5', 'abnormal_volume_10', 'abnormal_volume_20', 'abnormal_volume_30', 'abnormal_volume_60', 'volume_high_low_5', 'volume_high_low_10', 'volume_high_low_20', 'volume_high_low_30', 'volume_high_low_60', 'price_high_low_5', 'price_high_low_10', 'price_high_low_20', 'price_high_low_30', 'price_high_low_60', 'price_cog_5', 'price_cog_10', 'price_cog_20', 'price_cog_30', 'price_cog_60', 'p_v_corr0_5', 'p_v_corr0_10', 'p_v_corr0_20', 'p_v_corr0_30', 'p_v_corr0_60', 'p_v_corr1_5', 'p_v_corr1_10', 'p_v_corr1_20', 'p_v_corr1_30', 'p_v_corr1_60', 'p_v_cord_5', 'p_v_cord_10', 'p_v_cord_20', 'p_v_cord_30', 'p_v_cord_60', 'money_flow_5', 'money_flow_10', 'money_flow_20', 'money_flow_30', 'money_flow_60', 'order_imbalance_5', 'order_imbalance_10', 'order_imbalance_20', 'order_imbalance_30', 'order_imbalance_60', 'price_volatility_5', 'volume_volatility_5', 'price_volatility_10', 'volume_volatility_10', 'price_volatility_20', 'volume_volatility_20', 'price_volatility_30', 'volume_volatility_30', 'price_volatility_60', 'volume_volatility_60', 'Open time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close time', 'Quote asset volume', 'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume', 'Ignore', 'buy_ratio1', 'buy_ratio2']
        pred=model.predict(features[cols].loc[str(start_time)+'+08:00'].values.reshape([1,-1]))
        pred=np.array([pred]).flatten()[0]
        print(pred,start_time)

        symbol = f'1000PEPEUSDC'

        account_balance = float(client.futures_account_balance(asset='USDC')[0]['balance'])
        position1 =np.load('1000PEPEUSDCposition1.npy')[0]# float(client.futures_position_information(symbol=symbol)[0]['positionAmt'])  # 买仓数量
        position2 =np.load('1000PEPEUSDCposition2.npy')[0]# -float(client.futures_position_information(symbol=symbol)[1]['positionAmt']) if len(client.futures_position_information(symbol=symbol)) > 1 else 0  # 卖仓数量
        current_price = float(client.futures_symbol_ticker(symbol=symbol)['price'])

        fee = 0.017*0.9 / 100
        slippage = 0.02 / 100

        # 设置杠杆为40倍
        leverage = 1
        client.futures_change_leverage(symbol=symbol, leverage=leverage)

        key1, key2 = 0.00028333333333333335,-0.0007

        if pred < key1 and position1 > 0:
            # 卖出永续合约平仓
            order = client.futures_create_order(
                symbol=symbol,
                side=Client.SIDE_SELL,
                type=Client.ORDER_TYPE_MARKET,
                quantity=position1,
                reduceOnly=True,
                recvWindow=5000
            )
            account_balance += position1 * current_price * (1 - slippage) * (1 - fee) / leverage
            position1 = 0

        if pred > key2 and position2 > 0:
            # 买入永续合约平仓
            order = client.futures_create_order(
                symbol=symbol,
                side=Client.SIDE_BUY,
                type=Client.ORDER_TYPE_MARKET,
                quantity=position2,
                reduceOnly=True,
                recvWindow=5000
            )
            account_balance -= position2 * current_price * (1 + slippage) * (1 + fee) / leverage
            position2 = 0

        if pred > key1 and position1 == 0 and position2 == 0:
            # 计算10USDC保证金可买入的合约数量
            buy_quantity = 100 / (current_price * (1 + slippage) * (1 + fee) / leverage)
            buy_contracts = math.floor(buy_quantity * 10**0) / 10**0

            # 买入永续合约
            order = client.futures_create_order(
                symbol=symbol,
                side=Client.SIDE_BUY,
                type=Client.ORDER_TYPE_MARKET,
                quantity=buy_contracts,
                recvWindow=5000
            )
            position1 = buy_contracts
            account_balance -= buy_contracts * current_price * (1 + slippage) * (1 + fee) / leverage

        if pred < key2 and position1 == 0 and position2 == 0:
            # 计算10USDC保证金可卖出的合约数量
            sell_quantity = 100 / (current_price * (1 - slippage) * (1 - fee) / leverage)
            sell_contracts = math.floor(sell_quantity * 10**0) / 10**0

            # 卖出永续合约开空仓
            order = client.futures_create_order(
                symbol=symbol,
                side=Client.SIDE_SELL,
                type=Client.ORDER_TYPE_MARKET,
                quantity=sell_contracts,
                recvWindow=5000
            )
            position2 = sell_contracts
            account_balance += sell_contracts * current_price * (1 - slippage) * (1 - fee) / leverage
        np.save('1000PEPEUSDCposition1.npy',[position1])
        np.save('1000PEPEUSDCposition2.npy',[position2])
        np.save(f'autodl-tmp/1000PEPEUSDC{start_time}',pred)
from apscheduler.schedulers.blocking import BlockingScheduler
scheduler = BlockingScheduler()
scheduler.add_job(mainrun, 'cron',minute='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59') #实时下单
scheduler.start()
